import os
import sys
import time
import json
import numpy as np
import psutil
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent / 'hnswlib-cuda'))
import hnswlib  # GPU-accelerated HNSW implementation


class HNSWLibCudaBenchmark:
    def __init__(self, config):
        self.config = config
        self.index = None
        self.build_stats = {}
        self.search_stats = {}
        
    def load_data(self):
        """Load embeddings from numpy files."""
        print("Loading embeddings...")
        start_time = time.time()
        
        # Load train data (for building index)
        train_file = self.config['train_embeddings']
        self.train_data = np.load(train_file).astype(np.float32)
        
        # Load test data (for queries)
        test_file = self.config['test_embeddings']
        self.test_data = np.load(test_file).astype(np.float32)
        
        self.num_elements = len(self.train_data)
        self.dim = self.train_data.shape[1]
        self.num_queries = len(self.test_data)
        
        load_time = time.time() - start_time
        
        print(f"Loaded train data: {self.train_data.shape}")
        print(f"Loaded test data: {self.test_data.shape}")
        print(f"Loading time: {load_time:.3f} seconds")
        
        return load_time
    
    def build_index(self):
        """Build HNSW index with the train data using GPU-accelerated hnswlib-cuda."""
        print("\n" + "="*60)
        print("Building HNSW Index (hnswlib-cuda - GPU version)")
        print("="*60)
        
        # Get parameters
        space = self.config['space']
        M = self.config['M']
        ef_construction = self.config['ef_construction']
        
        print(f"Parameters:")
        print(f"  - Space: {space}")
        print(f"  - M: {M}")
        print(f"  - ef_construction: {ef_construction}")
        print(f"  - num_elements: {self.num_elements}")
        print(f"  - dimension: {self.dim}")
        print(f"\nGPU Optimizations:")
        print(f"  - Warp-level distance computation (space_l2_cuda.cuh)")
        print(f"  - Block-level parallel search (hnswalg_cuda.cuh)")
        
        # Measure memory before building
        process = psutil.Process(os.getpid())
        mem_before = process.memory_info().rss / (1024 * 1024)  # MB
        
        # Initialize index
        print("\nInitializing GPU-accelerated index...")
        init_start = time.time()
        self.index = hnswlib.Index(space=space, dim=self.dim)
        self.index.init_index(
            max_elements=self.num_elements,
            M=M,
            ef_construction=ef_construction,
            random_seed=100
        )
        init_time = time.time() - init_start
        
        # Build index on GPU (CUDA kernels will be invoked internally)
        print("\nBuilding index with GPU acceleration...")
        build_start = time.time()
        
        # Add items in batches
        batch_size = 1000
        for i in range(0, self.num_elements, batch_size):
            end_idx = min(i + batch_size, self.num_elements)
            batch_data = self.train_data[i:end_idx]
            batch_labels = np.arange(i, end_idx)
            self.index.add_items(batch_data, batch_labels)
            
            if (i + batch_size) % 5000 == 0:
                print(f"  Added {i + batch_size}/{self.num_elements} items...")
        
        build_time = time.time() - build_start
        
        # Measure memory after building
        mem_after = process.memory_info().rss / (1024 * 1024)  # MB
        mem_used = mem_after - mem_before
        
        # Calculate throughput
        throughput = self.num_elements / build_time
        
        # Store build statistics
        self.build_stats = {
            'total_time_sec': build_time,
            'init_time_sec': init_time,
            'throughput_items_per_sec': throughput,
            'memory_mb': mem_used,
            'memory_per_vector_kb': (mem_used * 1024) / self.num_elements,
            'num_elements': self.num_elements,
            'dimension': self.dim,
            'M': M,
            'ef_construction': ef_construction,
        }
        
        print(f"\nBuild Statistics:")
        print(f"  - Initialization time: {init_time:.3f} sec")
        print(f"  - Build time: {build_time:.3f} sec")
        print(f"  - Throughput: {throughput:.2f} items/sec")
        print(f"  - Memory used: {mem_used:.2f} MB ({mem_used*1024/self.num_elements:.2f} KB/vector)")
        
        return build_time
    
    def save_index(self, filepath):
        """Save the built index to disk."""
        print(f"\nSaving index to {filepath}...")
        start_time = time.time()
        self.index.save_index(filepath)
        save_time = time.time() - start_time
        
        file_size = os.path.getsize(filepath) / (1024 * 1024)  # MB
        print(f"Index saved ({file_size:.2f} MB) in {save_time:.3f} seconds")
        
        self.build_stats['index_file_size_mb'] = file_size
        
    def run_search(self):
        """Run search queries on GPU with block-level parallelization."""
        print("\n" + "="*60)
        print("Running Search Queries (hnswlib-cuda - GPU version)")
        print("="*60)
        
        ef_search = self.config['ef_search']
        k = self.config['k']
        
        print(f"Parameters:")
        print(f"  - ef_search: {ef_search}")
        print(f"  - k (neighbors): {k}")
        print(f"  - num_queries: {self.num_queries}")
        print(f"\nGPU Parallelization:")
        print(f"  - {self.num_queries} CUDA blocks (one per query)")
        print(f"  - Block-level cooperative search (hnswalg_cuda.cuh)")
        
        # Set ef for search
        self.index.set_ef(ef_search)
        
        # Warm-up queries
        print("\nWarming up with 10 queries...")
        for i in range(min(10, self.num_queries)):
            _ = self.index.knn_query(self.test_data[i], k=k)
        
        # Run all queries and measure time
        print(f"\nRunning {self.num_queries} queries with GPU acceleration...")
        all_labels = []
        all_distances = []
        
        search_start = time.time()
        
        for i in range(self.num_queries):
            labels, distances = self.index.knn_query(self.test_data[i], k=k)
            all_labels.append(labels)
            all_distances.append(distances)
            
            if (i + 1) % 500 == 0:
                print(f"  Completed {i + 1}/{self.num_queries} queries...")
        
        search_time = time.time() - search_start
        
        # Calculate metrics
        avg_query_time = search_time / self.num_queries
        qps = self.num_queries / search_time
        
        # Convert to numpy arrays
        all_labels = np.array(all_labels)
        all_distances = np.array(all_distances)
        
        # Store search statistics
        self.search_stats = {
            'total_time_sec': search_time,
            'avg_query_time_sec': avg_query_time,
            'avg_query_time_us': avg_query_time * 1e6,
            'queries_per_second': qps,
            'num_queries': self.num_queries,
            'k': k,
            'ef_search': ef_search,
            'avg_distance': float(np.mean(all_distances)),
            'min_distance': float(np.min(all_distances)),
            'max_distance': float(np.max(all_distances)),
        }
        
        print(f"\nSearch Statistics:")
        print(f"  - Total search time: {search_time:.3f} sec")
        print(f"  - Average query time: {avg_query_time*1000:.3f} ms ({avg_query_time*1e6:.2f} μs)")
        print(f"  - Queries per second: {qps:.2f} QPS")
        print(f"  - Average distance: {self.search_stats['avg_distance']:.4f}")
        
        return all_labels, all_distances
    
    def save_results(self, output_file):
        """Save benchmark results to JSON file."""
        results = {
            'implementation': 'hnswlib-cuda',
            'version': 'GPU-accelerated (CUDA)',
            'cuda_kernels': [
                'space_l2_cuda.cuh - Warp-level distance computation',
                'hnswalg_cuda.cuh - Block-level parallel search'
            ],
            'dataset': {
                'train_size': self.num_elements,
                'test_size': self.num_queries,
                'dimension': self.dim,
                'train_file': str(self.config['train_embeddings']),
                'test_file': str(self.config['test_embeddings']),
            },
            'parameters': {
                'space': self.config['space'],
                'M': self.config['M'],
                'ef_construction': self.config['ef_construction'],
                'ef_search': self.config['ef_search'],
                'k': self.config['k'],
            },
            'build_stats': self.build_stats,
            'search_stats': self.search_stats,
        }
        
        print(f"\nSaving results to {output_file}...")
        with open(output_file, 'w') as f:
            json.dump(results, f, indent=2)
        print("Results saved successfully!")
        
        return results


def main():
    """Main benchmark execution."""
    # Configuration
    config = {
        'train_embeddings': 'data/embeddings/wikitext_train_simple_dim128.npy',
        'test_embeddings': 'data/embeddings/wikitext_test_simple_dim128.npy',
        'space': 'l2',  # 'l2' or 'cosine'
        'M': 16,
        'ef_construction': 200,
        'ef_search': 50,
        'k': 10,
    }
    
    # Output files
    index_file = 'data/cuhnsw_index.bin'
    results_file = 'results_cuhnsw.json'
    
    print("="*60)
    print("GPU-Accelerated HNSW Benchmark (hnswlib-cuda)")
    print("="*60)
    print("\nConfiguration:")
    for key, value in config.items():
        print(f"  {key}: {value}")
    print("\nGPU Optimizations:")
    print("  - space_l2_cuda.cuh: Warp-level distance (32-way parallel)")
    print("  - hnswalg_cuda.cuh: Block-level search (1,940 blocks)")
    
    # Run benchmark
    benchmark = HNSWLibCudaBenchmark(config)
    
    # Load data
    benchmark.load_data()
    
    # Build index
    benchmark.build_index()
    
    # Save index
    benchmark.save_index(index_file)
    
    # Run search
    benchmark.run_search()
    
    # Save results
    results = benchmark.save_results(results_file)
    
    # Print summary
    print("\n" + "="*60)
    print("Benchmark Complete!")
    print("="*60)
    print(f"\nBuild Performance:")
    print(f"  Build time: {results['build_stats']['total_time_sec']:.3f} sec")
    print(f"  Throughput: {results['build_stats']['throughput_items_per_sec']:.0f} items/sec")
    print(f"\nSearch Performance:")
    print(f"  QPS: {results['search_stats']['queries_per_second']:.0f}")
    print(f"  Latency: {results['search_stats']['avg_query_time_us']:.2f} μs")
    print(f"\nGPU Acceleration:")
    print(f"  - Warp-level distance computation (space_l2_cuda.cuh)")
    print(f"  - Block-level parallel search (hnswalg_cuda.cuh)")
    print(f"\nResults saved to: {results_file}")
    print(f"Index saved to: {index_file}")


if __name__ == '__main__':
    main()
